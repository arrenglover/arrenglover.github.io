---
# Feel free to add content and custom Front Matter to this file.
# To modify the layout, see https://jekyllrb.com/docs/themes/#overriding-theme-defaults

layout: custom
---
# Research

## Tracking objects with an event-camera

| Event-cameras can be used for high frequency tracking of objects without motion-blur problems. |
|<video width="100%" video="100%" style="width:100%; height:100%" controls><source type="video/mp4" src="/assets/vid/robust_PF_c.mp4"></video>|
|<video width="100%" video="100%" style="width:100%; height:100%" controls><source type="video/mp4" src="/assets/vid/luv6DOF_c.mp4"></video>|
| <sub><sup>[A. Glover and C. Bartolozzi, "Robust visual tracking with a freely-moving event camera," 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2017, pp. 3769-3776, doi: 10.1109/IROS.2017.8206226.](https://ieeexplore.ieee.org/abstract/document/8206226)<br /><br /> [A. Glover and C. Bartolozzi, "Event-driven ball detection and gaze fixation in clutter," 2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2016, pp. 2203-2208, doi: 10.1109/IROS.2016.7759345.](https://ieeexplore.ieee.org/abstract/document/7759345)</sup></sub> |

## High-frequency Human Pose Estimation

| Lightweight neural networks can be trained with event data to perform complex tasks such as human pose estimation. |
|<video width="100%" video="100%" style="width:100%; height:100%" controls><source type="video/mp4" src="/assets/vid/HPEfusion_c.mp4"></video>|
| <sub><sup>[N. Carissimi, G. Goyal, F. D. Pietro, C. Bartolozzi and A. Glover, "[WIP] Unlocking Static Images for Training Event-driven Neural Networks," 2022 8th International Conference on Event-Based Control, Communication, and Signal Processing (EBCCSP), 2022, pp. 1-4, doi: 10.1109/EBCCSP56922.2022.9845526.](https://ieeexplore.ieee.org/abstract/document/9845526)</sup></sub> |

## Feature Points - Event-camera

| Low-level processing of the event-stream (e.g. corner detection, and convolutions) can be achieved in real-time with asynchronous output. |
|<video width="100%" video="100%" style="width:100%; height:100%" controls><source type="video/mp4" src="/assets/vid/luvHarris_c.mp4"></video>|
|<video width="100%" video="100%" style="width:100%; height:100%" controls><source type="video/mp4" src="/assets/vid/luvConv_c.mp4"></video>|
| <sub><sup>[A. Glover, A. Dinale, L. D. S. Rosa, S. Bamford and C. Bartolozzi, "luvHarris: A Practical Corner Detector for Event-Cameras," in IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 44, no. 12, pp. 10087-10098, 1 Dec. 2022, doi: 10.1109/TPAMI.2021.3135635.](https://ieeexplore.ieee.org/abstract/document/9652120)<br /><br /> [V. Vasco, A. Glover and C. Bartolozzi, "Fast event-based Harris corner detection exploiting the advantages of event-driven cameras," 2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2016, pp. 4144-4149, doi: 10.1109/IROS.2016.7759610.](https://ieeexplore.ieee.org/abstract/document/7759610)<br /><br />[L. d. S. Rosa, A. Dinale, S. Bamford, C. Bartolozzi and A. Glover, "High-Throughput Asynchronous Convolutions for High-Resolution Event-Cameras," 2022 8th International Conference on Event-Based Control, Communication, and Signal Processing (EBCCSP), 2022, pp. 1-8, doi: 10.1109/EBCCSP56922.2022.9845500.](https://ieeexplore.ieee.org/abstract/document/9845500)</sup></sub> |

### Appearance-based SLAM

| With the right algorithm autonomous vehicles can recognise where they are even in extreme weather conditions. |
| <object data='https://www.youtube.com/embed/NmyDFFFNCF4' width="100%" height="315"></object> |
| <video width="100%" video="100%" style="width:100%; height:100%" controls><source type="video/mp4" src="/assets/vid/fabmapratslam_c.mp4"></video> |
| <sub><sup>[A. J. Glover, W. P. Maddern, M. J. Milford and G. F. Wyeth, "FAB-MAP + RatSLAM: Appearance-based SLAM for multiple times of day," 2010 IEEE International Conference on Robotics and Automation, 2010, pp. 3507-3512, doi: 10.1109/ROBOT.2010.5509547.](https://ieeexplore.ieee.org/abstract/document/5509547)<br /><br /> [A. Glover, W. Maddern, M. Warren, S. Reid, M. Milford and G. Wyeth, "OpenFABMAP: An open source toolbox for appearance-based loop closure detection," 2012 IEEE International Conference on Robotics and Automation, 2012, pp. 4730-4735, doi: 10.1109/ICRA.2012.6224843.](https://ieeexplore.ieee.org/abstract/document/6224843)<br /><br />[M. Milford et al., "Condition-invariant, top-down visual place recognition," 2014 IEEE International Conference on Robotics and Automation (ICRA), 2014, pp. 5571-5577, doi: 10.1109/ICRA.2014.6907678.](https://ieeexplore.ieee.org/abstract/document/6907678>)</sup></sub> |


### Simple Affordance Learning

| Before Deep Neural Networks, learning could be achieved by on-line generation of models, such as Markov Decision Processes, allowing a robot to build their understanding of simple worlds and language. |
| <video width="100%" video="100%" style="width:100%; height:100%" controls><source type="video/mp4" src="/assets/vid/ACRA2010_c.mp4"></video> |
| <sub><sup>[A. J. Glover and G. F. Wyeth, "Toward Lifelong Affordance Learning Using a Distributed Markov Model," in IEEE Transactions on Cognitive and Developmental Systems, vol. 10, no. 1, pp. 44-55, March 2018, doi: 10.1109/TCDS.2016.2612721.](https://ieeexplore.ieee.org/abstract/document/7574281)<br /><br /> [R. Schulz, A. Glover, M. J. Milford, G. Wyeth and J. Wiles, "Lingodroids: Studies in spatial cognition and language," 2011 IEEE International Conference on Robotics and Automation, 2011, pp. 178-183, doi: 10.1109/ICRA.2011.5980476.](https://ieeexplore.ieee.org/abstract/document/5980476)</sup></sub>  |


